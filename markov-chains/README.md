# Markov Chains

## [`Markov Chains`](https://brilliant.org/wiki/markov-chains/)

* A `Markov chain` is a `stochastic process`, but it differs from a general stochastic process in that a Markov chain must be `memory-less`. 

* `State` `transitions` from one state to another according to certain `probabilistic rules`.

* No matter how the process arrived at its `present state`, the possible `future states are fixed`.

* The probability of transitioning to any particular state is dependent solely on the __current state__ and __time elapsed__.

* The state space, or set of all possible states, can be anything: letters, numbers, weather conditions, baseball scores, or stock performances.

* Markov chains may be modeled by `finite state machines`.
